{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train set :  (60000, 28, 28)\n",
      "Shape of the test set :  (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the MNIST dataset by splitting into train and test set\n",
    "\n",
    "trainset = MNIST(root='Desktop', train=True, download=True)\n",
    "testset  = MNIST(root='Desktop', train=False, download=True)\n",
    "\n",
    "trainset_array = trainset.data.numpy()\n",
    "testset_array  = testset.data.numpy()\n",
    "y_train_array = trainset.targets.numpy()\n",
    "y_test_array  = testset.targets.numpy()\n",
    "\n",
    "print('Shape of the train set : ', trainset_array.shape)\n",
    "print('Shape of the test set : ', testset_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_layer:\n",
    "\n",
    "    def __init__(self ,filter_size ,num_filters):\n",
    "\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_size = filter_size\n",
    "        self.filters = np.random.randn(num_filters, self.filter_size, self.filter_size) / self.filter_size**2\n",
    "    \n",
    "    def image_region(self, image):\n",
    "        '''\n",
    "        Generates all possible 3x3 image regions using valid padding.\n",
    "        \n",
    "        - image : numpy array\n",
    "        '''\n",
    "        h, w = image.shape\n",
    "        self.image = image\n",
    "        for i in range(h - self.filter_size + 1):\n",
    "            for j in range(w - self.filter_size + 1):\n",
    "                image_patch = image[i : (i + self.filter_size), j : (j + self.filter_size)]\n",
    "                yield image_patch, i, j\n",
    "        \n",
    "    def forward(self, image):\n",
    "        \n",
    "        '''\n",
    "    \n",
    "        Forward pass through the conv layer.\n",
    "        \n",
    "        - input : numpy array\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        h, w = image.shape\n",
    "        conv_output = np.zeros((h - self.filter_size + 1, w - self.filter_size + 1, self.num_filters))\n",
    "        for image_patch, i, j in self.image_region(image): \n",
    "            conv_output[i, j] = np.sum(image_patch*self.filters , axis=(1,2))\n",
    "        return conv_output\n",
    "\n",
    "    def backprop(self, dL_dout, lr):\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        Performs a backward pass of the conv layer.\n",
    "        \n",
    "        - dL_dout loss gradient backpropagated from the maxpool layer.\n",
    "        - lr : learning rate.\n",
    "        \n",
    "        '''\n",
    "        dL_dFilter = np.zeros(self.filters.shape)\n",
    "        for image_patch, i, j in self.image_region(self.image):\n",
    "            for k in range(self.num_filters):\n",
    "                dL_dFilter[k] += image_patch * dL_dout[i, j, k]\n",
    "        self.filters -= lr*dL_dFilter\n",
    "        return dL_dFilter\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Maxpool :\n",
    "    \n",
    "    def __init__(self, filter_size):\n",
    "        \n",
    "        self.filter_size = filter_size\n",
    "    \n",
    "    def image_region(self, image):\n",
    "        \n",
    "        '''\n",
    "        Returns non overlapping image regions\n",
    "        \n",
    "        - image : numpy array.\n",
    "        \n",
    "        '''\n",
    "        self.image = image\n",
    "        h = image.shape[0] // self.filter_size\n",
    "        w = image.shape[1] // self.filter_size\n",
    "        \n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                image_patch = image[(i * self.filter_size) : (i * self.filter_size + self.filter_size), \n",
    "                                            (j * self.filter_size) : (j * self.filter_size + self.filter_size)]\n",
    "                yield image_patch, i, j\n",
    "    \n",
    "    def forward(self, image):\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        Performs the forward pass and the maxpool operation.\n",
    "        \n",
    "        - image : numpy array.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        h, w, num_filters = image.shape\n",
    "        maxpool_output = np.zeros((h // self.filter_size, w // self.filter_size, num_filters))\n",
    "        \n",
    "        for image_patch, i, j in self.image_region(image):\n",
    "            maxpool_output[i, j] = np.amax(image_patch, axis = (0,1))\n",
    "        return maxpool_output\n",
    "    \n",
    "    def backprop(self, dL_dout):\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        Performs a backward pass of the maxpool layer.\n",
    "        Returns the loss gradient for this layer's inputs.\n",
    "        \n",
    "        - dL_dout : loss gradient backpropagated from the Softmax layer.\n",
    "        \n",
    "        '''\n",
    "        dL_dMaxpool = np.zeros(self.image.shape)\n",
    "        for image_patch, i, j in self.image_region(self.image):\n",
    "            \n",
    "            h, w, num_filters = image_patch.shape\n",
    "            max_val = np.amax(image_patch, axis = (0,1))\n",
    "            \n",
    "            for ii in range(h):\n",
    "                for jj in range(w):\n",
    "                    for kk in range(num_filters):\n",
    "                        if image_patch[ii, jj, kk] == max_val[kk]:\n",
    "                            dL_dMaxpool[(i * self.filter_size + ii), (j * self.filter_size + jj), kk] = dL_dout[i, j, kk]\n",
    "        \n",
    "        return dL_dMaxpool\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    \n",
    "    # fully connected layer with Softmax activation\n",
    "    \n",
    "    def __init__(self, input_node, softmax_node):\n",
    "        \n",
    "        self.weights = np.random.randn(input_node, softmax_node)/input_node\n",
    "        self.biaises = np.random.randn(softmax_node)\n",
    "        \n",
    "    def forward(self, image): \n",
    "        '''\n",
    "        \n",
    "        Forward pass of the image through the Softmax layer.\n",
    "        Returns a 1d numpy array containing the respective probability values.\n",
    "        \n",
    "        - image : numpy array.\n",
    "        '''\n",
    "        \n",
    "        self.orig_img_shape = image.shape\n",
    "        image_flat          = image.flatten()\n",
    "        self.flat_input     = image_flat\n",
    "        output_val          = np.dot(image_flat,self.weights) + self.biaises\n",
    "        self.out            = output_val\n",
    "        exp_output          = np.exp(output_val)\n",
    "        return exp_output / np.sum(exp_output, axis =0)\n",
    "    \n",
    "    def backprop(self, dL_dout, lr):\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        Performs a backward pass of the softmax layer.\n",
    "        Returns the loss gradient for this layer's inputs.\n",
    "        \n",
    "        - dL_dout : loss gradient.\n",
    "        - lr      : learning-rate\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        for i, grad in enumerate(dL_dout):\n",
    "            if grad == 0:\n",
    "                continue\n",
    "            \n",
    "            exp_z      = np.exp(self.out)\n",
    "            S          = np.sum(exp_z)\n",
    "            \n",
    "            dout_dz    = - exp_z[i] * exp_z / S**2\n",
    "            dout_dz[i] = exp_z[i] * (S - exp_z[i]) / S**2\n",
    "            \n",
    "            dz_dw      = self.flat_input\n",
    "            dz_db      = 1\n",
    "            dz_dinp    = self.weights\n",
    "            \n",
    "            dL_dz      = grad * dout_dz\n",
    "            dL_dw      = dz_dw[np.newaxis].T @ dL_dz[np.newaxis]\n",
    "            dL_db      = dL_dz * dz_db\n",
    "            dL_dinp    = dz_dinp @ dL_dz\n",
    "            \n",
    "            self.weights -= lr * dL_dw\n",
    "            self.biaises -= lr * dL_db\n",
    "            \n",
    "            return dL_dinp.reshape(self.orig_img_shape)\n",
    "        \n",
    "            \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST CNN initialized!\n",
      "--- Epoch 1 ---\n",
      "[Step 10000] Past 10000 steps: Average Loss 0.508 | Accuracy: 84%\n",
      "[Step 20000] Past 10000 steps: Average Loss 0.281 | Accuracy: 91%\n",
      "[Step 30000] Past 10000 steps: Average Loss 0.235 | Accuracy: 93%\n",
      "[Step 40000] Past 10000 steps: Average Loss 0.199 | Accuracy: 94%\n",
      "[Step 50000] Past 10000 steps: Average Loss 0.192 | Accuracy: 94%\n",
      "[Step 60000] Past 10000 steps: Average Loss 0.194 | Accuracy: 94%\n",
      "--- Epoch 2 ---\n",
      "[Step 10000] Past 10000 steps: Average Loss 0.165 | Accuracy: 95%\n",
      "[Step 20000] Past 10000 steps: Average Loss 0.181 | Accuracy: 94%\n",
      "[Step 30000] Past 10000 steps: Average Loss 0.177 | Accuracy: 94%\n",
      "[Step 40000] Past 10000 steps: Average Loss 0.200 | Accuracy: 94%\n",
      "[Step 50000] Past 10000 steps: Average Loss 0.171 | Accuracy: 95%\n",
      "[Step 60000] Past 10000 steps: Average Loss 0.196 | Accuracy: 94%\n",
      "--- Epoch 3 ---\n",
      "[Step 10000] Past 10000 steps: Average Loss 0.159 | Accuracy: 95%\n",
      "[Step 20000] Past 10000 steps: Average Loss 0.180 | Accuracy: 95%\n",
      "[Step 30000] Past 10000 steps: Average Loss 0.172 | Accuracy: 95%\n",
      "[Step 40000] Past 10000 steps: Average Loss 0.190 | Accuracy: 95%\n",
      "[Step 50000] Past 10000 steps: Average Loss 0.198 | Accuracy: 94%\n",
      "[Step 60000] Past 10000 steps: Average Loss 0.205 | Accuracy: 94%\n",
      "\n",
      "--- Testing the CNN ---\n",
      "Test Loss: 0.15543222116171726\n",
      "Test Accuracy: 0.9604\n",
      "CPU times: user 51min 15s, sys: 15.9 s, total: 51min 31s\n",
      "Wall time: 1h 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "conv = Conv_layer(8, 3)\n",
    "pool = Maxpool(2)\n",
    "softmax = Softmax(10 * 10 * 3, 10)\n",
    "\n",
    "\n",
    "def cnn_forward(images, labels):\n",
    "    '''\n",
    "      Forward pass through the network, returns the output of the network, cross-entropy loss\n",
    "      and the accuracy.\n",
    "      \n",
    "      - images : 2d numpy array\n",
    "      - labels : digit  \n",
    "    '''\n",
    "    output  = conv.forward((images / 255) - 0.5)\n",
    "    output  = pool.forward(output)\n",
    "    output  = softmax.forward(output)\n",
    "    \n",
    "    cross_ent = - np.log(output[labels])\n",
    "    accuracy  = 1 if np.argmax(output) == labels else 0\n",
    "    \n",
    "    return output, cross_ent, accuracy\n",
    "\n",
    "def train_cnn(images, labels, lr):\n",
    "    '''\n",
    "      Completes a full training step on the given image and label.\n",
    "      Returns the cross-entropy loss and accuracy.\n",
    "      \n",
    "      - images : 2d numpy array\n",
    "      - labels : digit\n",
    "      - lr     : learning rate\n",
    "  '''\n",
    "    \n",
    "    output, loss, acc = cnn_forward(images, labels)\n",
    "    \n",
    "    gradient = np.zeros(10)\n",
    "    \n",
    "    gradient[labels] = -1 / output[labels]\n",
    "    \n",
    "    gradback = softmax.backprop(gradient, lr)\n",
    "    gradback = pool.backprop(gradback)\n",
    "    gradback = conv.backprop(gradback, lr)\n",
    "    \n",
    "    return loss, acc\n",
    "\n",
    "print('MNIST CNN initialized!')\n",
    "\n",
    "# Train the CNN for 3 epochs\n",
    "for epoch in range(3):\n",
    "    print('--- Epoch %d ---' % (epoch + 1))\n",
    "\n",
    "  # Shuffle the training data\n",
    "    permutation = np.random.permutation(len(trainset_array))\n",
    "    train_images = trainset_array[permutation]\n",
    "    train_labels = y_train_array[permutation]\n",
    "\n",
    "  # Train!\n",
    "    loss = 0\n",
    "    num_correct = 0\n",
    "    for i, (im, label) in enumerate(zip(train_images, train_labels)):\n",
    "        if i > 0 and i % 10000 == 9999:\n",
    "            print(\n",
    "            '[Step %d] Past 10000 steps: Average Loss %.3f | Accuracy: %d%%' %\n",
    "                (i + 1, loss / 10000, num_correct/100)\n",
    "                  )\n",
    "            loss = 0\n",
    "            num_correct = 0\n",
    "\n",
    "        l, acc = train_cnn(im, label, 0.005)\n",
    "        loss += l\n",
    "        num_correct += acc\n",
    "\n",
    "# Test the CNN\n",
    "print('\\n--- Testing the CNN ---')\n",
    "loss = 0\n",
    "num_correct = 0\n",
    "\n",
    "for im, label in zip(testset_array, y_test_array):\n",
    "    _, l, acc = cnn_forward(im, label)\n",
    "    loss += l\n",
    "    num_correct += acc\n",
    "\n",
    "num_tests = len(y_test_array)\n",
    "print('Test Loss:', loss / num_tests)\n",
    "print('Test Accuracy:', num_correct / num_tests)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
